##    d) find the total votes (yes/no)
##    Consult the example in the API documentation that includes the relevant JSON result.
response4 <- GET(paste("https://api.propublica.org/congress/v1/members/", random_rep_id,
"/votes.json", sep=""), add_headers("X-API-Key" = propublica.key))
body4 <- content(response4, "text")
parsed_data4 <- fromJSON(body4)            #a
voting_data <- parsed_data4$results$votes  #b
position <- voting_data[[1]]$position      #c
num_votes <- NROW(position)
results <- voting_data[[1]]$result         #d
voting_history <- data_frame(position, results)
with_majority <- nrow(filter(voting_history, position == "Yes" & results == "Passed" |
position == "No" & results == "Failed"))
percent_with_majority <- with_majority / num_votes * 100
response <- GET("https://www.strava.com/oauth/authorize")
library(httr)
response <- GET("https://www.strava.com/oauth/authorize")
response
body <- content(response, "text")
parsed_data <- fromJSON(body)
library(jsonlite)
response <- GET("https://www.strava.com/oauth/authorize")
body <- content(response, "text")
parsed_data <- fromJSON(body)
View(parsed_data)
install.packages("t.test")
install.packages("tsum")
install.packages("bsda")
install.packages("BSDA")
library(BSDA)
?tsum.test
tsum.test(138.52, s.x = 7.76, n.x = 15, 149.07, s.y = 1.52, n.y = 20, alternative = "two.sided", conf.level = 0.05)
library(BSDM)
library(BSDA)
?tsum.test
tsum.test(-0.83, s.x = 0.172, n.x = 9,
-0.70, s.y = 0.184, n.y = 4,
alternative = "two.sided", conf.level = 0.01)
C6.3_df <- data.frame("Algeria" = 22,
"Bahrain" = 21,
"Belgium" = 29,
"Ethiopia" = c(21,25,17,24,21,22,21,22,21),
"Kenya" = c(21,19,18,22,20,30,20,28,22,20,27,21,21),
"Morocco" = c(32,28,29,24),
"Uganda" = 21)
install.packages("Kmisc")
install.packages("Kmisc")
C6.3_df <- data.frame("Algeria" = c(22,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,),
"Bahrain" = c(21,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,),
"Belgium" = c(29,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,),
"Ethiopia" = c(21,25,17,24,21,22,21,22,21,NA,NA,NA,NA),
"Kenya" = c(21,19,18,22,20,30,20,28,22,20,27,21,21),
"Morocco" = c(32,28,29,24,NA,NA,NA,NA,NA,NA,NA,NA,NA),
"Uganda" = c(21,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,))
C6.3_df <- data.frame("Algeria" = c(22,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA),
"Bahrain" = c(21,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA),
"Belgium" = c(29,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA),
"Ethiopia" = c(21,25,17,24,21,22,21,22,21,NA,NA,NA,NA),
"Kenya" = c(21,19,18,22,20,30,20,28,22,20,27,21,21),
"Morocco" = c(32,28,29,24,NA,NA,NA,NA,NA,NA,NA,NA,NA),
"Uganda" = c(21,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,))
C6.3_df <- data.frame("Algeria" = c(22,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA),
"Bahrain" = c(21,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA),
"Belgium" = c(29,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA),
"Ethiopia" = c(21,25,17,24,21,22,21,22,21,NA,NA,NA,NA),
"Kenya" = c(21,19,18,22,20,30,20,28,22,20,27,21,21),
"Morocco" = c(32,28,29,24,NA,NA,NA,NA,NA,NA,NA,NA,NA),
"Uganda" = c(21,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA))
View(C6.3_df)
CountryC6.3 <- c("Algeria", "Bahrain", "Belgium", "Ethiopia", "Ethiopia", "Ethiopia", "Ethiopia", "Ethiopia", "Ethiopia",
"Ethiopia", "Ethiopia", "Ethiopia", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya",
"Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Morocco", "Morocco", "Morocco", "Morocco", "Uganda")
CountryC6.3 <- c("Algeria", "Bahrain", "Belgium", "Ethiopia", "Ethiopia", "Ethiopia", "Ethiopia", "Ethiopia", "Ethiopia",
"Ethiopia", "Ethiopia", "Ethiopia", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya",
"Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Morocco", "Morocco", "Morocco", "Morocco", "Uganda")
AgeC6.3 <- c(22, 21, 29, 21, 25, 17, 24, 21, 22, 21, 22, 21, 21, 19, 18, 22, 20, 30, 20, 28, 22, 20, 27, 21, 21, 32, 28,
29, 24, 21)
as.data.frame(CountryC6.3, AgeC6.3)
as.data.frame(CountryC6.3, AgeC6.3, row.names=NULL)
CountryC6.3 <- c("Algeria", "Bahrain", "Belgium", "Ethiopia", "Ethiopia", "Ethiopia", "Ethiopia", "Ethiopia", "Ethiopia",
"Ethiopia", "Ethiopia", "Ethiopia", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya",
"Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Morocco", "Morocco", "Morocco", "Morocco", "Uganda")
AgeC6.3 <- c(22, 21, 29, 21, 25, 17, 24, 21, 22, 21, 22, 21, 21, 19, 18, 22, 20, 30, 20, 28, 22, 20, 27, 21, 21, 32, 28,
29, 24, 21)
C6.3_df <- as.data.frame(CountryC6.3, AgeC6.3, row.names=NULL)
aov.1 = aov(AgeC6.3 ~ as.factor(CountryC6.3), data=C6.3_df)
View(C6.3_df)
col1 <- c("Algeria", "Bahrain", "Belgium", "Ethiopia", "Ethiopia", "Ethiopia", "Ethiopia", "Ethiopia", "Ethiopia",
"Ethiopia", "Ethiopia", "Ethiopia", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya",
"Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Morocco", "Morocco", "Morocco", "Morocco", "Uganda")
col2 <- c(22, 21, 29, 21, 25, 17, 24, 21, 22, 21, 22, 21, 21, 19, 18, 22, 20, 30, 20, 28, 22, 20, 27, 21, 21, 32, 28,
29, 24, 21)
col1_name <- "country"
col2_name <- "age"
require(reshape2)
library(reshape2)
require(reshape2)
df <- melt(data.frame(col1, col2))
colnames(df) <- c(col1_name, col2_name)
print(df)
col1 <- c("Algeria", "Bahrain", "Belgium", "Ethiopia", "Ethiopia", "Ethiopia", "Ethiopia", "Ethiopia", "Ethiopia",
"Ethiopia", "Ethiopia", "Ethiopia", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya",
"Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Morocco", "Morocco", "Morocco", "Morocco", "Uganda")
col2 <- c(22, 21, 29, 21, 25, 17, 24, 21, 22, 21, 22, 21, 21, 19, 18, 22, 20, 30, 20, 28, 22, 20, 27, 21, 21, 32, 28,
29, 24, 21)
col1_name <- "country"
col2_name <- "age"
df <- melt(data.frame(col1, col2))
colnames(df) <- c(col1_name, col2_name)
print(df)
col1 <- c("Algeria", "Bahrain", "Belgium", "Ethiopia", "Ethiopia", "Ethiopia", "Ethiopia", "Ethiopia", "Ethiopia",
"Ethiopia", "Ethiopia", "Ethiopia", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya",
"Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Morocco", "Morocco", "Morocco", "Morocco", "Uganda")
col2 <- c(22, 21, 29, 21, 25, 17, 24, 21, 22, 21, 22, 21, 21, 19, 18, 22, 20, 30, 20, 28, 22, 20, 27, 21, 21, 32, 28,
29, 24, 21)
col1_name <- "country"
col2_name <- "age"
df <- melt(data.frame(col1, col2))
View(df)
col1 <- c("Algeria", "Bahrain", "Belgium", "Ethiopia", "Ethiopia", "Ethiopia", "Ethiopia", "Ethiopia", "Ethiopia",
"Ethiopia", "Ethiopia", "Ethiopia", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya",
"Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Morocco", "Morocco", "Morocco", "Morocco", "Uganda")
col2 <- c(22, 21, 29, 21, 25, 17, 24, 21, 22, 21, 22, 21, 21, 19, 18, 22, 20, 30, 20, 28, 22, 20, 27, 21, 21, 32, 28,
29, 24, 21)
col1_name <- "country"
col2_name <- "age"
df <- data.frame(col1, col2)
View(df)
colnames(df) <- c(col1_name, col2_name)
print(df)
col1 <- c("Algeria", "Bahrain", "Belgium", "Ethiopia", "Ethiopia", "Ethiopia", "Ethiopia", "Ethiopia", "Ethiopia",
"Ethiopia", "Ethiopia", "Ethiopia", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya",
"Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Morocco", "Morocco", "Morocco", "Morocco", "Uganda")
col2 <- c(22, 21, 29, 21, 25, 17, 24, 21, 22, 21, 22, 21, 21, 19, 18, 22, 20, 30, 20, 28, 22, 20, 27, 21, 21, 32, 28,
29, 24, 21)
df <- data.frame(col1, col2)
colnames(df) <- c("country", "age")
aov.1 = aov(AgeC6.3 ~ as.factor(CountryC6.3), data=C6.3_df)
aov.1 = aov(age ~ as.factor(country), data=df)
summary(aov.1)
boxplot(age ~ country, data=df)
col1 <- c("Algeria", "Bahrain", "Belgium", "Ethiopia", "Ethiopia", "Ethiopia", "Ethiopia", "Ethiopia", "Ethiopia",
"Ethiopia", "Ethiopia", "Ethiopia", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya",
"Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Morocco", "Morocco", "Morocco", "Morocco", "Uganda")
col2 <- c(22, 21, 29, 21, 25, 17, 24, 21, 22, 21, 22, 21, 21, 19, 18, 22, 20, 30, 20, 28, 22, 20, 27, 21, 21, 32, 28,
29, 24, 21)
df <- data.frame(col1, col2)
colnames(df) <- c("country", "age")
aov.c6.3 = aov(age ~ as.factor(country), data=df)
summary(aov.c.6.3)
col1 <- c("Algeria", "Bahrain", "Belgium", "Ethiopia", "Ethiopia", "Ethiopia", "Ethiopia", "Ethiopia", "Ethiopia",
"Ethiopia", "Ethiopia", "Ethiopia", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Kenya",
"Kenya", "Kenya", "Kenya", "Kenya", "Kenya", "Morocco", "Morocco", "Morocco", "Morocco", "Uganda")
col2 <- c(22, 21, 29, 21, 25, 17, 24, 21, 22, 21, 22, 21, 21, 19, 18, 22, 20, 30, 20, 28, 22, 20, 27, 21, 21, 32, 28,
29, 24, 21)
df <- data.frame(col1, col2)
colnames(df) <- c("country", "age")
aov.c6.3 <- aov(age ~ as.factor(country), data=df)
summary(aov.c6.3)
sigma <- 15    # theoretical standard deviation
mu0   <- 100   # expected value under H0
mu1   <- 101   # expected value under H1
alpha <- 0.01  # probability of type I error
# critical value for a level alpha test
crit <- qnorm(1-alpha, mu0, sigma)
# power: probability for values > critical value under H1
(pow <- pnorm(crit, mu1, sigma, lower.tail=FALSE))
# probability for type II error: 1 - power
(beta <- 1-pow)
sigma <- 15    # theoretical standard deviation
mu0   <- 100   # expected value under H0
mu1   <- 101   # expected value under H1
alpha <- 0.01  # probability of type I error
# critical value for a level alpha test
crit <- qnorm(1-alpha, mu0, sigma)
# power: probability for values > critical value under H1
(pow <- pnorm(crit, mu1, sigma, lower.tail=TRUE))
# probability for type II error: 1 - power
(beta <- 1-pow)
sigma <- 15    # theoretical standard deviation
mu0   <- 100   # expected value under H0
mu1   <- 100   # expected value under H1
alpha <- 0.01  # probability of type I error
# critical value for a level alpha test
crit <- qnorm(1-alpha, mu0, sigma)
# power: probability for values > critical value under H1
(pow <- pnorm(crit, mu1, sigma, lower.tail=FALSE))
# probability for type II error: 1 - power
(beta <- 1-pow)
sigma <- 15    # theoretical standard deviation
mu0   <- 100   # expected value under H0
mu1   <- 101   # expected value under H1
alpha <- 0.01  # probability of type I error
# critical value for a level alpha test
crit <- qnorm(1-alpha, mu0, sigma)
# power: probability for values > critical value under H1
(pow <- pnorm(crit, mu1, sigma, lower.tail=FALSE))
# probability for type II error: 1 - power
(beta <- 1-pow)
# EXAMPLE 2
n = 100                # sample size
sigma = 15           # population standard deviation
sem = sigma/sqrt(n); sem   # standard error
alpha = .01           # significance level
mu0 = 101          # hypothetical lower bound
q = qnorm(alpha, mean=mu0, sd=sem); q
mu = 100             # assumed actual mean
pnorm(q, mean=mu, sd=sem, lower.tail=FALSE)
n = 100                    # sample size
sigma = 15                 # population standard deviation
sem = sigma/sqrt(n); sem   # standard error
alpha = .01                # significance level
mu0 = 101                  # hypothetical lower bound
q = qnorm(alpha, mean=mu0, sd=sem); q
mu = 100                   # assumed actual mean
pnorm(q, mean=mu, sd=sem, lower.tail=FALSE)
n = 400                    # sample size
sigma = 15                 # population standard deviation
sem = sigma/sqrt(n); sem   # standard error
alpha = .01                # significance level
mu0 = 101                  # hypothetical lower bound
q = qnorm(alpha, mean=mu0, sd=sem); q
mu = 100                   # assumed actual mean
pnorm(q, mean=mu, sd=sem, lower.tail=FALSE)
n = 1600                    # sample size
sigma = 15                 # population standard deviation
sem = sigma/sqrt(n); sem   # standard error
alpha = .01                # significance level
mu0 = 101                  # hypothetical lower bound
q = qnorm(alpha, mean=mu0, sd=sem); q
mu = 100                   # assumed actual mean
pnorm(q, mean=mu, sd=sem, lower.tail=FALSE)
n = 2500                    # sample size
sigma = 15                 # population standard deviation
sem = sigma/sqrt(n); sem   # standard error
alpha = .01                # significance level
mu0 = 101                  # hypothetical lower bound
q = qnorm(alpha, mean=mu0, sd=sem); q
mu = 100                   # assumed actual mean
pnorm(q, mean=mu, sd=sem, lower.tail=FALSE)
# inflated and the remainder (1181-882 = 299) were contricted.
# Is there evidence to contradict Mendel's theory?
# This is a test of 2 proportions (proportion inflated, proportion constricted)
# from one population.
# The null hypothesis is that the proportion inflated is 0.75 and
# the proportion constricted is 0.25.
# The alternative is that the null is not true.
# In lecture we tested this with a "Z-test" and also a chi-square test.
# (With only 2 categories, the z-test and chi-square test are the same.)
# Here, we use the chi-square test.
obscounts = c(882,299)      # Note the data are entered as *counts*.
pi0 = c(0.75, 0.25) # But the null values are given as proportions.
chisq.test(obscounts,p=pi0 ) # This can be confusing. Be careful!
# Text Example 8.9 presents the counts of reasons for which cans do not meet
# specification (blemish on can, crack in can, improper pull tab, pull tab missing,
# other) from 3 different can production lines (lines 1, 2, 3)
# The observed counts are provided as obscounts below.
# The rows correspond to production lines 1, 2 and 3.
# The columns correspond to the 5 reasons: blemish on can, crack in can,
# improper pull tab, pull tab missing, other
obscounts<-matrix(c(34,65,17,21,13,
23,52,25,19,6,
32,28,16,14,10),3,5, byrow=T)
rownames(obscounts) <- c("line1", "line2", "line3")
colnames(obscounts) <- c("blemish", "crack", "improperTab", "missingTab", "other")
obscounts
chisq.test(obscounts)
# For Text problem 8.52, a random sample of individuals who drive to work in a
# large metropolitan area was obtained, and each individual was categorized with
# respect to both size of vehicle and commuting distance (in miles).
#
# The null hypothesis is that vehicle and commuting distance are independent.
# The alternative hypothesis is that vehicle and commuting distance or dependent.
#
# The data are given in obscounts below:
# The rows correspond to vehicle type (subcompact, compact, midsize, fullsize).
# The columns correspond to distance (0-<10,10-<20,>=20).
obscounts<-matrix(c(6,27,19,
8,36,17,
21,45,33,
14,18,6),4,3, byrow=T)
obscounts
chisq.test(obscounts)
# Here is the above chi-squared test "by hand," i.e., without chisq.test():
total = sum(obscounts)
rowsum = apply(obscounts,1,sum)
colsum = apply(obscounts,2,sum)
expected = (matrix(rowsum) %*% t(matrix(colsum))) / total
expected      # Don't worry about the details of the above %*% operation.
resid = (obscounts-expected)/sqrt(expected)
df = prod(dim(obscounts)-1)  # This df is just the product (nrow-1)(ncol-1)
X2 = sum(resid^2)            # = observed X-squared.
1-pchisq(X2,df)    # p-value = area under the chi-squared distribution
dat = read.table("http://faculty.washington.edu/lynb/StatMath390/9_1_dat.txt",header=TRUE)
aov.1 = aov(Vibration~ as.factor(Brand), data=dat)
# Remember "as.factor" is important. It tells R to treat Brand as a categorical variable
# with categories 1, 2, ..., 5
# instead of as a continuous variable with values 1, ..., 5
# With as.factor(Brand), the F-test has 4 numerator degrees of freedom (for 5-1 categories)
summary(aov.1)  # you can compare this to Table 9.1 in the textbook, or to doing it by hand further below
# NOTE: If you omit, "as.factor", then the F-test has only 1 numerator degrees of freedom
# It is NOT a test of the null hypothesis that the mean vibration is the same across brands!
summary(aov(Vibration~ (Brand), data=dat))
# Look at the summary of the test of the null hypothesis that the mean vibration is the same across brands
summary(aov.1)
boxplot(Vibration ~ Brand, data=dat)
dat = read.table("http://faculty.washington.edu/lynb/StatMath390/9_1_dat.txt",header=TRUE)
attach(dat)
# If you have only means and standard deviations from data, then R does not know
# how to do ANOVA. Then, you must do it "by hand," i.e., using the basic formulas.
#
# For doing a 1-way ANOVA test, let's compute the mean and standard deviation
# for the data in Table 9.1, then use the basic ANOVA equations to show that we
# get the same answers as above.
?attach
k = 5                          # number of categories.
n = m = s = numeric(k)         # space for mean and sd in each category.
for(i in 1:k){
n[i] = length(dat[Brand==i,2])                        # sample size in each category, and
m[i] = mean(dat[Brand==i,2])   # mean in each category, and
s[i] = sd(dat[Brand==i,2])     # standard dev in each category.
}                              # Ignore R warnings, if any.
n
m
s
# Let's do ANOVA by hand (i.e. using the basic anova equations):
N = sum(n)                       # total number of observations
k = length(n)                    # number of categories.
df1 = k-1                        # numerator df.
df2 = N-k                        # denominator df.
grand.ave = sum(m * n) / N       # grand average.
SSB = sum(n*(m - grand.ave)^2)   # sum-squared between groups.
SSW = sum((n-1)*s^2 )            # sum-squared within groups. Recall that s^2 = sum of squares / (n-1).
MSB = SSB/df1                    # mean-squared between groups.
MSW = SSW/df2                    # mean-squared within groups.
F = MSB/MSW                      # F-ratio
p.value = 1-pf(F,df1,df2)        # p-value. Note pf(F,df1,df2) and pf(F,df2,df1) give different results!
df1 ; df2 ; SSB ; SSW ; MSB ; MSW ; F ; p.value   # same as anova table above.
# Look at the summary of the test of the null hypothesis that the mean vibration is the same across brands
summary(aov.1)
# inflated and the remainder (1181-882 = 299) were contricted.
# Is there evidence to contradict Mendel's theory?
# This is a test of 2 proportions (proportion inflated, proportion constricted)
# from one population.
# The null hypothesis is that the proportion inflated is 0.75 and
# the proportion constricted is 0.25.
# The alternative is that the null is not true.
# In lecture we tested this with a "Z-test" and also a chi-square test.
# (With only 2 categories, the z-test and chi-square test are the same.)
# Here, we use the chi-square test.
obscounts = c(60,10,30)      # Note the data are entered as *counts*.
pi0 = c(.33333, .33333, .33333) # But the null values are given as proportions.
chisq.test(obscounts,p=pi0 ) # This can be confusing. Be careful!
# inflated and the remainder (1181-882 = 299) were contricted.
# Is there evidence to contradict Mendel's theory?
# This is a test of 2 proportions (proportion inflated, proportion constricted)
# from one population.
# The null hypothesis is that the proportion inflated is 0.75 and
# the proportion constricted is 0.25.
# The alternative is that the null is not true.
# In lecture we tested this with a "Z-test" and also a chi-square test.
# (With only 2 categories, the z-test and chi-square test are the same.)
# Here, we use the chi-square test.
obscounts = c(60,10,30)      # Note the data are entered as *counts*.
pi0 = c(1/3, 1/3, 1/3) # But the null values are given as proportions.
chisq.test(obscounts,p=pi0 ) # This can be confusing. Be careful!
col1 <- c(1,1,2,2,3,3,4,4)
col2 <- c(30.8, 27.2, 24.7, 26.1, 25.1, 23.8, 24.5, 29.8)
col1 <- c(1,1,2,2,3,3,4,4)
col2 <- c(30.8, 27.2, 24.7, 26.1, 25.1, 23.8, 24.5, 29.8)
df <- data.frame(col1, col2)
colnames(df) <- c("manufacturer", "foam_density")
View(df)
aov.c6.3 <- aov(df$col2 ~ as.factor(df$col1), data=df)
aov.c6.3 <- aov(foam_density ~ as.factor(manufacturer), data=df)
col1 <- c(1,1,2,2,3,3,4,4)
col2 <- c(30.8, 27.2, 24.7, 26.1, 25.1, 23.8, 24.5, 29.8)
df <- data.frame(col1, col2)
colnames(df) <- c("manufacturer", "foam_density")
aov.2 <- aov(foam_density ~ as.factor(manufacturer), data=df)
summary(aov.2)
q11.4x <- c(2, 12, 14, 17, 23, 30, 40, 47,
55, 67, 72, 81, 96, 112, 27)
q11.4y <- c(4, 10, 13, 15, 15, 25, 27, 46,
38, 46, 53, 70, 82, 99, 100)
plot(q11.4x, q11.4y)
summary(q11.4y ~ q11.4x)
lm(q11.4y ~ q11.4x)
summmary(lm(q11.4y ~ q11.4x))
summary(lm(q11.4y ~ q11.4x))
q11.4x <- c(5, 12, 14, 17, 23, 30, 40, 47,
55, 67, 72, 81, 96, 112, 27)
q11.4y <- c(4, 10, 13, 15, 15, 25, 27, 46,
38, 46, 53, 70, 82, 99, 100)
plot(q11.4x, q11.4y)
lm(q11.4y ~ q11.4x)
q11.4x <- c(5, 12, 14, 17, 23, 30, 40, 47,
55, 67, 72, 81, 96, 112, 127)
q11.4y <- c(4, 10, 13, 15, 15, 25, 27, 46,
38, 46, 53, 70, 82, 99, 100)
plot(q11.4x, q11.4y)
lm(q11.4y ~ q11.4x)
summary(lm(q11.4y ~ q11.4x))
anova(lm(q11.4y ~ q11.4x))
q11.4x <- c(5, 12, 14, 17, 23, 30, 40, 47,
55, 67, 72, 81, 96, 112, 127)
q11.4y <- c(4, 10, 13, 15, 15, 25, 27, 46,
38, 46, 53, 70, 82, 99, 100)
plot(q11.4x, q11.4y)
lm(q11.4y ~ q11.4x)
summary(lm(q11.4y ~ q11.4x))
anova(lm(q11.4y ~ q11.4x))
fit = lm(q11.4y ~ q11.4x)
summary(fit)$r.square
sse = sum((fitted(fit) - mean(q11.4x))^2)
sse = sum((fitted(fit) - mean(q11.4y))^2)
sxx <- sum((q11.4x-mean(q11.4x))^2)
sxx
q11.22x <- c(.11,.13,.14,.18,.29,.44,.67,.78,.93)
q11.22y <- c(1.72,2.17,2.33,3,5.17,7.61,11.17,12.72,14.78)
summary(lm(q11.22y ~ q11.22x))
mean(q11.22x)
16.0593 * 0.4077778 + 0.1925
(16.0593 * 0.4077778 + 0.1925) / 2
plot(q11.22x, q11.22y)
mean(q11.22x)
sxx <- sum((q11.22x-mean(q11.22x))^2)
sxx
sxx <- sum((q11.4x-mean(q11.4x))^2)
sxx
q11.4x <- c(5, 12, 14, 17, 23, 30, 40, 47,
55, 67, 72, 81, 96, 112, 127)
q11.4y <- c(4, 10, 13, 15, 15, 25, 27, 46,
38, 46, 53, 70, 82, 99, 100)
sxx <- sum((q11.4x-mean(q11.4x))^2)
sxx
summary(lm(q11.4y ~ q11.4x))
source("keys.R")
setwd("~/Desktop/Autumn 2018/info/FINAL PROJECT/Crime-vs-Weather")
query_params <- list(address = address, key = weather.key)
query_params <- list(address = address, key = google.key)
## Install the required package with:
install.packages("RSocrata")
library("RSocrata")
weather.key <- "LohlCfXXXfYI7xjWHo8PBNHhr"
email <- "rekisela@uw.edu"
password <- "RacKis98!"
library("RSocrata")
source("keys.R")
df <- read.socrata(
"https://data.seattle.gov/resource/b3ws-t8sc.csv",
app_token = weather.key,
email     = email,
password  = password
)
View(df)
library("RSocrata")
source("keys.R")
df <- read.socrata(
"https://data.seattle.gov/resource/b3ws-t8sc.json",
app_token = weather.key,
email     = email,
password  = password
)
View(df)
df <- read.socrata(
"https://data.seattle.gov/resource/b3ws-t8sc.json",
app_token = "LohlCfXXXfYI7xjWHo8PBNHhr",
email     = "rekisela@uw.edu",
password  = "RacKis98!"
)
library("RSocrata")
source("keys.R")
df <- read.socrata(
"https://data.seattle.gov/resource/b3ws-t8sc.json",
app_token = "LohlCfXXXfYI7xjWHo8PBNHhr",
email     = "rekisela@uw.edu",
password  = "RacKis98!"
)
View(df)
?read.socrata
df <- read.socrata(
"https://data.seattle.gov/resource/b3ws-t8sc.json",
app_token = "LohlCfXXXfYI7xjWHo8PBNHhr",
stringsAsFactors = FALSE
)
library("RSocrata")
source("keys.R")
df <- read.socrata(
"https://data.seattle.gov/resource/b3ws-t8sc.json",
app_token = "LohlCfXXXfYI7xjWHo8PBNHhr",
stringsAsFactors = FALSE
)
View(df)
View(df)
df <- read.socrata(
"https://data.seattle.gov/resource/b3ws-t8sc.json?location_city=Seattle",
app_token = "LohlCfXXXfYI7xjWHo8PBNHhr",
stringsAsFactors = FALSE
)
View(df)
df <- read.socrata(
"https://data.seattle.gov/resource/b3ws-t8sc.json?location_city=SEATTLE",
app_token = "LohlCfXXXfYI7xjWHo8PBNHhr",
stringsAsFactors = FALSE
)
df <- read.socrata(
"https://data.seattle.gov/resource/b3ws-t8sc.json?location_city=seattle",
app_token = "LohlCfXXXfYI7xjWHo8PBNHhr",
stringsAsFactors = FALSE
)
?aggregate
